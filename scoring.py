import numpy as np
from collections import defaultdict
import requests

class GlobalScorer:
    def __init__(self, api_key,lambda_penalty=0.5, model="glm-4v-flash"):
        self.lambda_penalty = lambda_penalty
        self.api_key = api_key
        self.original_prompt = None
        self.optimized_prompt = None
        self.quality_summary = None
        self.model = model
        assert isinstance(lambda_penalty, (int, float)), \
            f"lambda_penalty å¿…é¡»æ˜¯æ•°å€¼ï¼Œå®žé™…æ˜¯ {type(lambda_penalty)}"
        self.lambda_penalty = float(lambda_penalty)  # å¼ºåˆ¶è½¬æ¢
        
    def compute_final_score(self, mos_cq, mos_tc, explanations_cq, explanations_tc, prompt_text):
        # ç±»åž‹å®‰å…¨æ£€æŸ¥
        print(mos_cq,mos_tc)
        # è®¡ç®—åŸºç¡€åˆ†
        base_score = 0.5 * (mos_cq + mos_tc)
        print("111")
        # è®¡ç®—æƒ©ç½šé¡¹ï¼ˆå†…éƒ¨å·²åšç±»åž‹æ£€æŸ¥ï¼‰
        penalty = self._calculate_penalty(mos_cq, mos_tc)
        print("222")
        # æœ€ç»ˆè¯„åˆ†
        self.lambda_penalty * penalty
        print("333")
        final_score = np.clip(base_score + self.lambda_penalty * penalty, 0, 1)
        print("444")
        # ç”Ÿæˆåé¦ˆ
        feedback = self._generate_feedback(explanations_cq, explanations_tc, mos_cq, mos_tc, prompt_text)
        
        return final_score, feedback

    def _calculate_penalty(self, mos_cq, mos_tc):
        """æ ¹æ®è®ºæ–‡è¡¨1è®¡ç®—æƒ©ç½šé¡¹"""
        # é«˜è´¨é‡ä½†æ„å›¾æœªè¡¨è¾¾ (CQé«˜ï¼ŒTCä½Ž)
        if mos_cq >= 0.7 and mos_tc <= 0.4:
            return -0.1
        
        # ç¬¦åˆæ„å›¾ä½†è´¨é‡å·® (TCé«˜ï¼ŒCQä½Ž)
        elif mos_tc >= 0.7 and mos_cq <= 0.4:
            return -0.05
        
        # ä¸¥é‡å¤±çœŸä¸”ä¸ç¬¦è¯­ä¹‰ (åŒä½Ž)
        elif mos_cq <= 0.4 and mos_tc <= 0.4:
            return -0.3
        
        # é«˜è´¨é‡å›¾åƒä¸æƒ©ç½š
        else:
            print("555")
            return 0
    def _generate_feedback(self, explanations_cq, explanations_tc, mos_cq, mos_tc, prompt_text):
        # æž„å»ºå¤§æ¨¡åž‹æç¤º
        analysis_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIç”Ÿæˆè´¨é‡åˆ†æžå¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹è¯„ä¼°æ•°æ®ç”Ÿæˆè´¨é‡æ€»ç»“å’Œä¼˜åŒ–åŽçš„æç¤ºè¯ï¼Œä¼˜åŒ–åŽçš„æç¤ºè¯ä¸€å®šæ˜¯ä¸ºäº†è§£å†³ç›®å‰çš„é—®é¢˜è€Œç”Ÿçš„ï¼š
                            [åŽŸå§‹æç¤ºè¯]
                            {prompt_text}
                            [å†…å®¹è´¨é‡è¯„ä¼°]ï¼ˆå¾—åˆ†ï¼š{mos_cq:.2f}/1.0ï¼‰
                            {str(explanations_cq)}
                            [å›¾æ–‡ä¸€è‡´æ€§è¯„ä¼°]ï¼ˆå¾—åˆ†ï¼š{mos_tc:.2f}/1.0ï¼‰
                            {str(explanations_tc)}
                            è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
                            ### è´¨é‡æ€»ç»“ï¼ˆçŸ­æ‘˜è¦ï¼‰ ###
                            ### ä¼˜åŒ–åŽçš„æç¤ºè¯ ###
                        """
        try:
            print(111)
            print(str(explanations_cq))
            # è°ƒç”¨å¤§æ¨¡åž‹API
            headers = {"Authorization": f"Bearer {self.api_key}"}
            response = requests.post(
                "https://open.bigmodel.cn/api/paas/v4/chat/completions",
                json={
                    "model": self.model,
                    "messages": [{
                        "role": "user", 
                        "content": analysis_prompt
                    }]
                },
                headers=headers,
                timeout=15
            )
            return response.json()["choices"][0]["message"]["content"]

        except Exception as e:
            return f"""### è´¨é‡æ€»ç»“ ###
                        å†…å®¹è´¨é‡è¯„åˆ†ï¼š{mos_cq:.2f}
                        å›¾æ–‡ä¸€è‡´è¯„åˆ†ï¼š{mos_tc:.2f}
                        ### ä¼˜åŒ–æç¤º ###
                        {prompt_text}, enhanced quality"""


if __name__ == "__main__":
    # æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
    mos_cq = 1.0  # å‡è®¾å›¾åƒè´¨é‡è¾ƒå·®
    mos_tc = 1.0  # å›¾æ–‡ä¸€è‡´æ€§è¾ƒå¥½
    prompt_text = "A giraffe walking through a green grass covered field"

    # æ¨¡æ‹Ÿä¸‰ä¸ªæ™ºèƒ½ä½“ã€ä¸¤è½®çš„è§£é‡Šæ•°æ®ï¼ˆæ¯è½®æ¯ä¸ªé—®é¢˜ä¸€ä¸ªè§£é‡Šï¼‰
    explanations_cq = [
        {0: ["0 + é•¿é¢ˆé¹¿è…¿éƒ¨æ¯”ä¾‹ä¸åè°ƒ", "0 + è‰åœ°çº¹ç†é‡å¤", "1 + å›¾åƒè¾¹ç¼˜æ¸…æ™°"]},
        {0: ["0 + ç»“æž„ä¸è‡ªç„¶", "0 + è‰åœ°é¢œè‰²åˆ†å¸ƒä¸å‡", "1 + ç»†èŠ‚è¡¨çŽ°è‰¯å¥½"]},
        {0: ["0 + é•¿é¢ˆé¹¿å¤´èº«æ¯”ä¾‹å¼‚å¸¸", "0 + èƒŒæ™¯æœ‰æ··åˆä¼ªå½±", "1 + æ²¡æœ‰æ¨¡ç³Š"]},
    ]

    explanations_tc = [
        {0: ["1 + å›¾åƒä¸­æœ‰é•¿é¢ˆé¹¿", "1 + è‰åœ°ç»¿è‰²æ˜Žæ˜¾", "1 + ç¬¦åˆâ€œè¡Œèµ°â€è¯­ä¹‰"]},
        {0: ["1 + ç‰©ä½“ä¸Žæç¤ºä¸€è‡´", "1 + èƒŒæ™¯åœºæ™¯æ­£ç¡®", "1 + åŠ¨ä½œè¡¨è¾¾æ¸…æ™°"]},
        {0: ["1 + å­˜åœ¨æŒ‡å®šåŠ¨ç‰©", "1 + ç»¿è‰²è‰åœ°å¯è¾¨", "1 + åŠ¨ä½œä¸Žæç¤ºåŒ¹é…"]},
    ]

    # åˆå§‹åŒ– scorer
    scorer = GlobalScorer(api_key="74a5a65105194797a4613f0b921266ba.N1y1c5frioiFJFvA")

    # è¿è¡Œè¯„åˆ†ä¸Žåé¦ˆ
    score, feedback = scorer.compute_final_score(
        mos_cq=mos_cq,
        mos_tc=mos_tc,
        explanations_cq=explanations_cq,
        explanations_tc=explanations_tc,
        prompt_text=prompt_text
    )

    print("ðŸŸ¢ æœ€ç»ˆè¯„åˆ†ï¼š", score)
    print("\nðŸ“‹ åé¦ˆå»ºè®®ï¼š")
    print(feedback)